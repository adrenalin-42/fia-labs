{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d252a8d",
   "metadata": {
    "id": "7d252a8d"
   },
   "source": [
    "***FCIM.FIA - Fundamentals of Artificial Intelligence***\n",
    "\n",
    "> **Lab 5:** *Computer Vision* \\\n",
    "> **Performed by:** *Dumitru Moraru*, group *FAF-212* \\\n",
    "> **Verified by:** Elena Graur, asist. univ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BPiGwyyGNsHh",
   "metadata": {
    "id": "BPiGwyyGNsHh"
   },
   "source": [
    "Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fd9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T09:47:05.838671Z",
     "start_time": "2022-01-23T09:47:05.834860Z"
    },
    "id": "533fd9fa"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ed9b",
   "metadata": {
    "id": "7146ed9b"
   },
   "source": [
    "# Part 1 Imports and Global Configuration\n",
    "This initial section loads the necessary libraries and defines the core parameters that control the detection and tracking behavior. These act as the main settings for the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants and Configuration ---\n",
    "VIDEO_PATH = 'cars.mp4' \n",
    "PIXELS_PER_METER = 20\n",
    "SPEED_LIMIT_KMH = 60\n",
    "\n",
    "# --- Detection Tuning Parameters ---\n",
    "MIN_CONTOUR_AREA = 1500\n",
    "MIN_ASPECT_RATIO = 0.6\n",
    "MAX_ASPECT_RATIO = 1.5\n",
    "MAX_TRACKING_DISTANCE = 60\n",
    "FRAMES_TO_DISAPPEAR = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b08ea7",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* The system ensures the existence of a directory for storing face data.\n",
    "* New face encodings are saved as `.npy` (NumPy array) files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938e3e4",
   "metadata": {
    "id": "0938e3e4"
   },
   "source": [
    "# Part 2 The VehicleTracker Class\n",
    "This class is the \"brain\" of the tracking logic. It is responsible for maintaining a memory of detected vehicles from one frame to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0859a4",
   "metadata": {
    "id": "6b0859a4"
   },
   "outputs": [],
   "source": [
    "class VehicleTracker:\n",
    "    \"\"\"A simple class to track vehicles using centroid tracking.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.tracked_objects = {}\n",
    "        self.next_id = 0\n",
    "\n",
    "    def register(self, centroid, rect):\n",
    "        \"\"\"Registers a new vehicle.\"\"\"\n",
    "        self.tracked_objects[self.next_id] = {\n",
    "            'centroid': centroid,\n",
    "            'rect': rect,\n",
    "            'speed_kmh': 0,\n",
    "            'frames_without_detection': 0\n",
    "        }\n",
    "        self.next_id += 1\n",
    "\n",
    "    def deregister(self, object_id):\n",
    "        \"\"\"Removes a vehicle from tracking.\"\"\"\n",
    "        # Make sure the key exists before trying to delete it\n",
    "        if object_id in self.tracked_objects:\n",
    "            del self.tracked_objects[object_id]\n",
    "\n",
    "    def update(self, detected_centroids, fps):\n",
    "        \"\"\"Updates the state of tracked vehicles.\"\"\"\n",
    "\n",
    "        # If there are no detected centroids, increment disappearance counter for all tracked objects.\n",
    "        if not detected_centroids:\n",
    "            for obj_id in list(self.tracked_objects.keys()):\n",
    "                self.tracked_objects[obj_id]['frames_without_detection'] += 1\n",
    "                if self.tracked_objects[obj_id]['frames_without_detection'] > FRAMES_TO_DISAPPEAR:\n",
    "                    self.deregister(obj_id)\n",
    "            return self.tracked_objects\n",
    "\n",
    "        # If no objects are being tracked yet, register all new detections.\n",
    "        if not self.tracked_objects:\n",
    "            for centroid, rect in detected_centroids:\n",
    "                self.register(centroid, rect)\n",
    "            return self.tracked_objects\n",
    "\n",
    "        # Prepare to match detected centroids to existing tracked objects.\n",
    "        object_ids = list(self.tracked_objects.keys())\n",
    "        previous_centroids = np.array([obj['centroid'] for obj in self.tracked_objects.values()])\n",
    "        current_centroids = np.array([c[0] for c in detected_centroids])\n",
    "\n",
    "        # Ensure there are centroids to compare before calculating distance\n",
    "        if len(previous_centroids) == 0 or len(current_centroids) == 0:\n",
    "            if len(current_centroids) > 0:\n",
    "                 for centroid, rect in detected_centroids:\n",
    "                    is_new = True\n",
    "                    for obj in self.tracked_objects.values():\n",
    "                        if np.array_equal(obj['centroid'], centroid):\n",
    "                           is_new = False\n",
    "                           break\n",
    "                    if is_new:\n",
    "                        self.register(centroid, rect)\n",
    "            return self.tracked_objects\n",
    "\n",
    "\n",
    "        # Calculate distances between each previous centroid and each current centroid.\n",
    "        D = cdist(previous_centroids, current_centroids)\n",
    "\n",
    "        # Find the best match for each tracked object.\n",
    "        rows = D.min(axis=1).argsort()\n",
    "        cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "        used_rows = set()\n",
    "        used_cols = set()\n",
    "\n",
    "        for (row, col) in zip(rows, cols):\n",
    "            if row in used_rows or col in used_cols:\n",
    "                continue\n",
    "\n",
    "            if D[row, col] > MAX_TRACKING_DISTANCE:\n",
    "                continue\n",
    "\n",
    "            obj_id = object_ids[row]\n",
    "            new_centroid, new_rect = detected_centroids[col]\n",
    "            old_centroid = self.tracked_objects[obj_id]['centroid']\n",
    "\n",
    "            distance_pixels = math.hypot(new_centroid[0] - old_centroid[0], new_centroid[1] - old_centroid[1])\n",
    "            distance_meters = distance_pixels / PIXELS_PER_METER\n",
    "\n",
    "            if fps > 0:\n",
    "                speed_mps = distance_meters * fps\n",
    "                speed_kmh = speed_mps * 3.6\n",
    "                self.tracked_objects[obj_id]['speed_kmh'] = 0.9 * self.tracked_objects[obj_id]['speed_kmh'] + 0.1 * speed_kmh\n",
    "            else:\n",
    "                self.tracked_objects[obj_id]['speed_kmh'] = 0\n",
    "\n",
    "            self.tracked_objects[obj_id]['centroid'] = new_centroid\n",
    "            self.tracked_objects[obj_id]['rect'] = new_rect\n",
    "            self.tracked_objects[obj_id]['frames_without_detection'] = 0\n",
    "\n",
    "            used_rows.add(row)\n",
    "            used_cols.add(col)\n",
    "\n",
    "        unused_rows = set(range(0, D.shape[0])).difference(used_rows)\n",
    "        for row in unused_rows:\n",
    "            obj_id = object_ids[row]\n",
    "            self.tracked_objects[obj_id]['frames_without_detection'] += 1\n",
    "            if self.tracked_objects[obj_id]['frames_without_detection'] > FRAMES_TO_DISAPPEAR:\n",
    "                self.deregister(obj_id)\n",
    "\n",
    "        unused_cols = set(range(0, D.shape[1])).difference(used_cols)\n",
    "        for col in unused_cols:\n",
    "            self.register(detected_centroids[col][0], detected_centroids[col][1])\n",
    "\n",
    "        return self.tracked_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2f6ed",
   "metadata": {},
   "source": [
    "* It calculates the distance between every previously tracked object and every newly detected object.\n",
    "* It finds the best matches based on the smallest distances.\n",
    "* For each successful match, it updates the vehicle's position and calculates its new speed based on the distance traveled since the last frame.\n",
    "* It registers any new, unmatched detections as new vehicles.\n",
    "* It increments a \"disappeared\" counter for any tracked vehicles that were not found in the current frame and deregisters them if they've been missing for too long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67a3d5",
   "metadata": {
    "id": "3f67a3d5"
   },
   "source": [
    "# Part 3 Main Application Logic\n",
    "This is the primary execution block of the script, containing the main `while` loop that processes the video frame by frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046623ad",
   "metadata": {
    "id": "046623ad"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file at {VIDEO_PATH}\")\n",
    "    exit()\n",
    "\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "tracker = VehicleTracker()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream.\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    fg_mask = bg_subtractor.apply(blurred)\n",
    "    _, thresh = cv2.threshold(fg_mask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Refined morphological operations for better noise removal\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opened_mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    dilated_mask = cv2.dilate(opened_mask, kernel, iterations=3)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detected_centroids = []\n",
    "    for cnt in contours:\n",
    "        contour_area = cv2.contourArea(cnt)\n",
    "        if contour_area > MIN_CONTOUR_AREA:\n",
    "            rect = cv2.boundingRect(cnt)\n",
    "            x, y, w, h = rect\n",
    "\n",
    "            # *** NEW: Filter by Aspect Ratio ***\n",
    "            if h > 0: # Avoid division by zero\n",
    "                aspect_ratio = float(w) / h\n",
    "                if aspect_ratio > MIN_ASPECT_RATIO and aspect_ratio < MAX_ASPECT_RATIO:\n",
    "                    M = cv2.moments(cnt)\n",
    "                    if M['m00'] != 0:\n",
    "                        cx = int(M['m10'] / M['m00'])\n",
    "                        cy = int(M['m01'] / M['m00'])\n",
    "                        detected_centroids.append(((cx, cy), rect))\n",
    "\n",
    "    tracked_objects = tracker.update(detected_centroids, video_fps)\n",
    "\n",
    "    speeding_count = 0\n",
    "    for obj_id, data in tracked_objects.items():\n",
    "        rect = data['rect']\n",
    "        speed = data['speed_kmh']\n",
    "        x, y, w, h = rect\n",
    "\n",
    "        is_speeding = speed > SPEED_LIMIT_KMH\n",
    "        box_color = (0, 0, 255) if is_speeding else (0, 255, 0)\n",
    "\n",
    "        if is_speeding:\n",
    "            speeding_count += 1\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 2)\n",
    "        speed_text = f\"{speed:.1f} km/h\"\n",
    "        cv2.putText(frame, speed_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "\n",
    "    total_vehicles = len(tracked_objects)\n",
    "    info_text_total = f\"Detected Vehicles: {total_vehicles}\"\n",
    "    info_text_speeding = f\"Speeding: {speeding_count}\"\n",
    "    cv2.putText(frame, info_text_total, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "    cv2.putText(frame, info_text_speeding, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Vehicle Speed Detection', frame)\n",
    "    # cv2.imshow('Foreground Mask', dilated_mask)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1a2f7",
   "metadata": {},
   "source": [
    "-   **Image Pre-processing**: The frame is converted to grayscale and blurred. This reduces detail and noise, making the subsequent motion detection more reliable.\n",
    "-   **Background Subtraction**: The `fg_mask` is created, which is a black-and-white image where white pixels represent foreground motion.\n",
    "-   **Mask Cleaning**: Morphological operations (`MORPH_OPEN` and `dilate`) are applied to the mask. This cleans up small noise artifacts and fills holes in the detected objects, resulting in cleaner, more solid shapes.\n",
    "-   **Contour Detection**: `cv2.findContours` is used to find the outlines of all the white shapes in the cleaned mask.\n",
    "-   **Contour Filtering**: The script iterates through every detected contour and filters them based on the tuning parameters (`MIN_CONTOUR_AREA` and aspect ratio). Only contours that are large enough and have a car-like shape are kept. The centroids of these valid contours are stored.\n",
    "-   **Tracker Update**: The list of valid centroids is passed to `tracker.update()`. The tracker performs its matching logic and returns the updated state of all tracked vehicles.\n",
    "-   **Visualization**: The code loops through the tracked objects from the tracker. For each vehicle, it draws a bounding box (red for speeding, green otherwise) and displays its calculated speed on the original frame. Summary text (total detected vehicles, speeding count) is also added.\n",
    "-   **Display**: `cv2.imshow(...)` displays the final processed frame in a window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29d59a",
   "metadata": {
    "id": "0e29d59a"
   },
   "source": [
    "# Conclusions:\n",
    "This project successfully a vehicle speed detection system using Python and OpenCV. The program effectively identifies, tracks, and calculates the speed of cars in video footage by using background subtraction and centroid tracking. While the system is efficient, its accuracy depends on stable lighting and camera calibration. Future improvements could involve implementing a Region of Interest (ROI) to focus detection or upgrading to a deep learning model like YOLO for more robust performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwGzGeqmzU-l",
   "metadata": {
    "id": "zwGzGeqmzU-l"
   },
   "source": [
    "# Bibliography:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5DrArOXRzWet",
   "metadata": {
    "id": "5DrArOXRzWet"
   },
   "source": [
    "1) https://opencv.org/\n",
    "2) https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "3) https://www.geeksforgeeks.org/find-and-draw-contours-using-opencv-python/\n",
    "4) https://pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/\n",
    "5) https://www.myzhar.com/blog/tutorials/tutorial-opencv-ball-tracker-using-kalman-filter/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
