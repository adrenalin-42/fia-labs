{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d252a8d",
   "metadata": {
    "id": "7d252a8d"
   },
   "source": [
    "***FCIM.FIA - Fundamentals of Artificial Intelligence***\n",
    "\n",
    "> **Lab 4:** *Machine Learning* \\\n",
    "> **Performed by:** *Dumitru Moraru*, group *FAF-212* \\\n",
    "> **Verified by:** Elena Graur, asist. univ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BPiGwyyGNsHh",
   "metadata": {
    "id": "BPiGwyyGNsHh"
   },
   "source": [
    "Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fd9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T09:47:05.838671Z",
     "start_time": "2022-01-23T09:47:05.834860Z"
    },
    "id": "533fd9fa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ed9b",
   "metadata": {
    "id": "7146ed9b"
   },
   "source": [
    "# Task 1\n",
    "The dataset is loaded using Pandas, and basic information is displayed, including missing values and column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine quality dataset\n",
    "file_path = 'wine-quality-white-and-red.csv'\n",
    "wine_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Preview of the dataset:\")\n",
    "print(wine_data.head())\n",
    "\n",
    "# Display information about the dataset (columns, data types, non-null values)\n",
    "print(\"\\nDataset Information:\")\n",
    "print(wine_data.info())\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = wine_data.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b08ea7",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* The dataset is read from a CSV file.\n",
    "* First 5 rows and column details are displayed.\n",
    "* Checks for missing values to ensure data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938e3e4",
   "metadata": {
    "id": "0938e3e4"
   },
   "source": [
    "# Task 2\n",
    "If the dataset contains categorical columns (e.g., `type` for red or white wine), they are converted into numerical format using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0859a4",
   "metadata": {
    "id": "6b0859a4"
   },
   "outputs": [],
   "source": [
    "# Convert categorical column 'type' to numerical using one-hot encoding (if present)\n",
    "if 'type' in wine_data.columns:\n",
    "    print(\"\\nConverting wine type to numerical values\")\n",
    "    wine_data = pd.get_dummies(wine_data, columns=['type'], drop_first=True)\n",
    "    # Note: drop_first=True avoids multicollinearity by removing one redundant column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2f6ed",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* Converts categorical values (e.g., red or white) into numerical values (0 or 1).\n",
    "* Drops one of the categories to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67a3d5",
   "metadata": {
    "id": "3f67a3d5"
   },
   "source": [
    "# Task 3\n",
    "The target variable is wine quality, which is converted into a binary classification:\n",
    "\n",
    "* Good (1): Quality â‰¥6\n",
    "* Bad (0): Quality <6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046623ad",
   "metadata": {
    "id": "046623ad"
   },
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = wine_data.drop(columns=['quality'])  # All columns except 'quality' are features\n",
    "y = wine_data['quality']                 # 'quality' is the target variable\n",
    "\n",
    "# Convert quality rating into binary classification:\n",
    "# Good quality (1): rating >= 6\n",
    "# Bad quality (0): rating < 6\n",
    "y = np.where(y >= 6, 1, 0)\n",
    "print(f\"\\nClass distribution after binarization: {np.bincount(y)}\")\n",
    "print(f\"Positive class (Good wine) percentage: {np.mean(y) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1a2f7",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* `X` contains all features except `quality`.\n",
    "* `y` is transformed into a binary classification based on quality thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137588a",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "The dataset is split into training (80%) and testing (20%) sets. The features are standardized using StandardScaler to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89064d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "# random_state ensures reproducibility, stratify maintains class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Standardize features: rescaling to mean=0 and variance=1\n",
    "# This is important for models like SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit to training data and transform it\n",
    "X_test = scaler.transform(X_test)        # Apply same transformation to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8bdd9",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* Stratified splitting ensures balanced class distribution.\n",
    "* Feature scaling standardizes data to improve ML model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca4e07",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Three machine learning models are trained and compared:\n",
    "\n",
    "* Logistic Regression\n",
    "* Random Forest Classifier\n",
    "* Support Vector Machine (SVM)\n",
    "\n",
    "Each model is evaluated using:\n",
    "\n",
    "* Accuracy Score\n",
    "* Classification Report (Precision, Recall, F1-Score)\n",
    "* Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classification models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracy results for comparison\n",
    "results = {}\n",
    "\n",
    "# Train each model and evaluate performance\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Training and evaluating: {name}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and store in results dictionary\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(f\"\\n{name} Model Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Display detailed classification metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Create and display confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6d309",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* Each model is trained on `X_train`, `y_train` and predicts on `X_test`.\n",
    "* The accuracy is calculated and stored for comparison.\n",
    "* A classification report is displayed to evaluate performance metrics.\n",
    "* Confusion matrix visualizes correct vs incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f15c43",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "The accuracy scores of the three models are compared using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to compare the performance of all models\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    results.keys(), \n",
    "    results.values(), \n",
    "    color=['#3498db', '#2ecc71', '#e74c3c']\n",
    ")\n",
    "\n",
    "# Add data labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2.,\n",
    "        height + 0.01,\n",
    "        f'{height:.4f}',\n",
    "        ha='center', \n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Classification Model\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Comparison of Wine Quality Classification Models\")\n",
    "plt.ylim(0, 1)  # Set y-axis limits from 0 to 1 (accuracy range)\n",
    "plt.xticks(rotation=15)  # Rotate labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213be5ad",
   "metadata": {},
   "source": [
    "Explanation\n",
    "* Bar chart compares the accuracy of different models.\n",
    "* Different colors represent each model's accuracy.\n",
    "* Y-axis is limited between 0 and 1 for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b7af7",
   "metadata": {},
   "source": [
    "![1.png](./1.png)\n",
    "![2.png](./2.png)\n",
    "![3.png](./3.png)\n",
    "![4.png](./4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29d59a",
   "metadata": {
    "id": "0e29d59a"
   },
   "source": [
    "# Conclusions:\n",
    "This lab successfully demonstrates wine quality classification using machine learning. The results indicate that:\n",
    "\n",
    "* Feature engineering and standardization improve model performance.\n",
    "* Random Forest Classifier is the most effective model for this dataset.\n",
    "* Confusion matrices and classification reports provide deeper insights into model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwGzGeqmzU-l",
   "metadata": {
    "id": "zwGzGeqmzU-l"
   },
   "source": [
    "# Bibliography:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5DrArOXRzWet",
   "metadata": {
    "id": "5DrArOXRzWet"
   },
   "source": [
    "1) https://www.geeksforgeeks.org/ml-linear-regression/\n",
    "2) https://trendspider.com/learning-center/linear-regression-intercept-predicting-future-values-and-trends/\n",
    "3) https://scikit-learn.org/1.5/modules/linear_model.html\n",
    "4) https://medium.com/@hannah.hj.do/getting-to-know-lars-least-angle-regression-f50e94c34b97\n",
    "5) https://scikit-learn.org/1.5/api/sklearn.metrics.html#module-sklearn.metrics\n",
    "6) https://www.geeksforgeeks.org/clustering-in-machine-learning/\n",
    "7) https://www.geeksforgeeks.org/k-means-clustering-introduction/\n",
    "8) https://scikit-learn.org/1.5/api/sklearn.cluster.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
