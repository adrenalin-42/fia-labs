{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d252a8d",
   "metadata": {
    "id": "7d252a8d"
   },
   "source": [
    "***FCIM.FIA - Fundamentals of Artificial Intelligence***\n",
    "\n",
    "> **Lab 6:** *Natural Language Processing* \\\n",
    "> **Performed by:** *Dumitru Moraru*, group *FAF-212* \\\n",
    "> **Verified by:** Elena Graur, asist. univ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BPiGwyyGNsHh",
   "metadata": {
    "id": "BPiGwyyGNsHh"
   },
   "source": [
    "Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fd9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T09:47:05.838671Z",
     "start_time": "2022-01-23T09:47:05.834860Z"
    },
    "id": "533fd9fa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ed9b",
   "metadata": {
    "id": "7146ed9b"
   },
   "source": [
    "# Part 1\n",
    "A custom dataset was created containing forgiving and angry sentiment examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with example boss messages and their sentiment labels\n",
    "training_data = {\n",
    "    \"message\": [\n",
    "        # \"Angry\" boss messages\n",
    "        \"I expected this report on my desk yesterday. What happened?\",\n",
    "        \"This performance is simply unacceptable. We need to talk.\",\n",
    "        \"Did you even proofread this before sending it to me?\",\n",
    "        \"I'm still waiting for that analysis I requested last week.\",\n",
    "        \"Your presentation was disorganized and unprofessional.\",\n",
    "        \"I don't have time for excuses. I need results.\",\n",
    "        \"This is the third time you've missed this deadline.\",\n",
    "        \"These numbers don't add up. Fix this immediately.\",\n",
    "        \"I'm disappointed by your lack of attention to detail.\",\n",
    "        \"Why wasn't I informed about this issue earlier?\",\n",
    "        \"The client is furious. How could you let this happen?\",\n",
    "        \"Your absence from yesterday's meeting was noted.\",\n",
    "        \"This isn't what I asked for at all. Start over.\",\n",
    "        \"You need to take more responsibility for your errors.\",\n",
    "        \"I can't believe we're still discussing this problem.\",\n",
    "        \n",
    "        # \"Forgiving\" boss messages\n",
    "        \"Let's discuss how we can improve this process moving forward.\",\n",
    "        \"I see the effort you've put into this project.\",\n",
    "        \"Your recent work shows significant improvement.\",\n",
    "        \"I appreciate you taking initiative on this task.\",\n",
    "        \"We all make mistakes. Let's find a solution together.\",\n",
    "        \"I think you're on the right track with this approach.\",\n",
    "        \"Your ideas in the meeting yesterday were insightful.\",\n",
    "        \"I'd like to hear your thoughts on how to resolve this.\",\n",
    "        \"Thanks for staying late to finish the project.\",\n",
    "        \"This report is much better than the previous version.\",\n",
    "        \"I'm giving you another opportunity to demonstrate your skills.\",\n",
    "        \"Let's set up a time to review your progress.\",\n",
    "        \"I noticed the extra effort you've been putting in lately.\",\n",
    "        \"Your contribution to the team has been valuable.\",\n",
    "        \"I believe you have potential to excel in this role.\"\n",
    "    ] * 3,  # Repeat to increase dataset size\n",
    "    \n",
    "    \"sentiment\": [\n",
    "        # Sentiment labels corresponding to the messages above\n",
    "        \"angry\", \"angry\", \"angry\", \"angry\", \"angry\",\n",
    "        \"angry\", \"angry\", \"angry\", \"angry\", \"angry\",\n",
    "        \"angry\", \"angry\", \"angry\", \"angry\", \"angry\",\n",
    "        \n",
    "        \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\",\n",
    "        \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\",\n",
    "        \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\", \"forgiving\"\n",
    "    ] * 3  # Repeat to match the message repetition\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b08ea7",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* The dataset consists of text messages and their corresponding sentiment labels (either \"forgiving\" or \"angry\").\n",
    "* To ensure a balanced dataset, sentences are repeated four times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938e3e4",
   "metadata": {
    "id": "0938e3e4"
   },
   "source": [
    "# Part 2\n",
    "Before training, we need to clean the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0859a4",
   "metadata": {
    "id": "6b0859a4"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess boss's cryptic messages for sentiment analysis.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to preprocess\n",
    "        \n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # Handle missing values\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2f6ed",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "1. Convert to lowercase\n",
    "2. Remove special characters and numbers\n",
    "3. Tokenize into individual words\n",
    "4. Remove common stopwords\n",
    "5. Join back into a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67a3d5",
   "metadata": {
    "id": "3f67a3d5"
   },
   "source": [
    "# Part 3\n",
    "Once the text is cleaned, we need to convert it into a numerical format using TF-IDF (Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046623ad",
   "metadata": {
    "id": "046623ad"
   },
   "outputs": [],
   "source": [
    "# Transform text data into TF-IDF features\n",
    "X_train = vectorizer.fit_transform(df_train[\"cleaned_message\"])\n",
    "y_train = df_train[\"sentiment\"]\n",
    "X_predict = vectorizer.transform(df_predict[\"cleaned_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1a2f7",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* TF-IDF vectorization converts words into numerical values based on their importance in the dataset.\n",
    "* The higher the TF-IDF score, the more important the word is for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137588a",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "To train the model effectively, the dataset is split into training (80%) and testing (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89064d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training on {X_train_split.shape[0]} examples, testing on {X_test_split.shape[0]} examples\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8bdd9",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* The Naïve Bayes classifier is trained using the processed dataset.\n",
    "* Multinomial Naïve Bayes is ideal for text-based classification tasks due to its probabilistic nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca4e07",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "To assess the model’s performance, we use accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on the test set\n",
    "y_pred = model.predict(X_test_split)\n",
    "accuracy = accuracy_score(y_test_split, y_pred)\n",
    "report = classification_report(y_test_split, y_pred)\n",
    "cm = confusion_matrix(y_test_split, y_pred)\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6d309",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* The model’s predictions are compared to actual labels to determine accuracy.\n",
    "* The classification report provides insights into precision, recall, and F1-score for each sentiment class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f3847",
   "metadata": {},
   "source": [
    "# Part 6\n",
    "To avoid retraining the model every time, we save it using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, model_path)\n",
    "joblib.dump(vectorizer, vectorizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac639277",
   "metadata": {},
   "source": [
    "To load and reuse the model later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b71d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(model_path)\n",
    "vectorizer = joblib.load(vectorizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657aa28",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* Saving the trained model allows it to be reused without retraining.\n",
    "* Joblib is used because it efficiently stores machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729014ee",
   "metadata": {},
   "source": [
    "# Part 7\n",
    "Once the model is trained, we can use it to predict sentiment for new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for checking boss's current mood\n",
    "prediction_data = {\n",
    "    \"message\": [\n",
    "        \"I'm expecting a comprehensive explanation for this failure.\",\n",
    "        \"Perhaps we should revisit your approach to this assignment.\",\n",
    "        \"I'd like to see your revised plan by tomorrow morning.\",\n",
    "        \"Let's schedule a meeting to discuss your performance.\",\n",
    "        \"Your recent report showed some interesting insights.\",\n",
    "        \"I noticed you've been putting in extra hours lately.\",\n",
    "        \"This isn't what I asked for. Do it again.\",\n",
    "        \"We need to address these ongoing issues promptly.\",\n",
    "        \"I'm giving you one more chance to prove yourself.\",\n",
    "        \"Your teamwork on the latest project was commendable.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ------------------ Data Preparation ------------------\n",
    "\n",
    "# Convert dictionaries to pandas DataFrames\n",
    "df_train = pd.DataFrame(training_data)\n",
    "df_predict = pd.DataFrame(prediction_data)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Training dataset size: {len(df_train)} examples\")\n",
    "print(f\"Prediction dataset size: {len(df_predict)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef594aa2",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "* The model processes new sentences and predicts their sentiment.\n",
    "* The TF-IDF vectorizer transforms the input text, ensuring compatibility with the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29d59a",
   "metadata": {
    "id": "0e29d59a"
   },
   "source": [
    "# Conclusions:\n",
    "This laboratory work successfully implemented sentiment analysis using Natural Language Processing and Machine Learning techniques. The Naïve Bayes classifier trained on TF-IDF-transformed text demonstrated high accuracy in classifying forgiving and angry sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwGzGeqmzU-l",
   "metadata": {
    "id": "zwGzGeqmzU-l"
   },
   "source": [
    "# Bibliography:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5DrArOXRzWet",
   "metadata": {
    "id": "5DrArOXRzWet"
   },
   "source": [
    "1) https://www.ibm.com/topics/recurrent-neural-networks\n",
    "2) https://medium.com/@rebeen.jaff/what-is-lstm-introduction-to-long-short-term-memory-66bd3855b9ce\n",
    "3) https://www.baeldung.com/cs/lstm-vanishing-gradient-prevention\n",
    "4) https://medium.com/@anishnama20/understanding-gated-recurrent-unit-gru-in-deep-learning-2e54923f3e2\n",
    "5) https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#:~:text=A%20Sequence%20to%20Sequence%20network%2C%20or%20seq2seq%20network%2C%20or%20Encoder,to%20produce%20an%20output%20sequence.\n",
    "6) https://medium.com/@rubyabdullah14/building-a-telegram-bot-with-python-a-step-by-step-guide-5ca305bea6c0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
